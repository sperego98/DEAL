from __future__ import annotations

from dataclasses import dataclass,field,asdict
from typing import List, Optional, Sequence
from typing import List, Dict, Any

import numpy as np
import sys
from pprint import pformat
import json
from copy import deepcopy

from ase.io import iread, write
from ase.calculators.singlepoint import SinglePointCalculator

from flare.learners.utils import is_std_in_bound
from flare.atoms import FLARE_Atoms

from .utils import create_chemiscope_input

@dataclass
class DataConfig:
    # --- data / trajectory ---
    files: List[str]
    format: Optional[str] = None
    index: str = ":"                 # ASE selection string
    colvar: Optional[List[str]] = None
    shuffle: bool = False 
    seed: int = 42 

@dataclass
class DEALConfig:
    # --- selection parameters ---
    threshold: float = 1.0
    update_threshold: Optional[float] = None
    max_atoms_added: int = -1
    min_steps_with_model: int = 0     # frames between two selections

    # --- GP training options ---
    force_only: bool = True           # ignore energies/stress if True
    train_hyps: bool = False          # train hyperparams after each update

    # --- output ---
    output_prefix: str = "deal"
    verbose: bool = False
    save_gp: bool = False

@dataclass
class FlareConfig:
    # --- gp ---
    gp: str = "SGP_Wrapper"

    # --- kernel ---
    kernels: List[Dict[str, Any]] = field(default_factory=lambda: [
        {"name": "NormalizedDotProduct", "sigma": 2.0, "power": 2}
    ])
    # --- descriptor ---
    descriptors: List[Dict[str, Any]] = field(default_factory=lambda: [
        {
            "name": "B2",
            "nmax": 8,
            "lmax": 3,
            "cutoff_function": "cosine",
            "radial_basis": "chebyshev",
        }
    ])
    # --- species ---
    species: list[int] = None 
    # --- parameters ---
    cutoff: float = 4.5
    variance_type: str = "local"
    max_iterations: int = 20

class DEAL:
    """
    Minimal DEAL-style selector:

    - iterate over a trajectory (ASE files)
    - for each frame:
        * read energy/forces/stress from the file
        * evaluate SGP and its uncertainties
        * if uncertainty is above threshold -> "select" frame and update SGP

    Outputs:
        <output_prefix>_selected.xyz
        <output_prefix>_flare.json
        <output_prefix>_chemiscope.json.gz
    """

    def __init__(self, 
                 data_cfg: DataConfig, 
                 deal_cfg: DEALConfig, 
                 flare_cfg: FlareConfig):
        
        self.data_cfg = data_cfg
        self.deal_cfg = deal_cfg
        self.flare_cfg = flare_cfg

        # Check if a single traj or a list is provided
        if isinstance(self.data_cfg.files, str):
            self.data_cfg.files = [self.data_cfg.files]

        # Automatically detect species if not specified
        if self.flare_cfg.species is None:
            self.flare_cfg.species = self._get_species()

        # Print configuratons is requested:
        if self.deal_cfg.verbose:
            print('[INFO] Configurations:')
            print('-',pformat(self.data_cfg))
            print('-',pformat(self.deal_cfg))
            print('-',pformat(self.flare_cfg))
            print('')

        # Build SGP calculator 
        self.flare_calc, self.kernels = self._get_sgp_calc(asdict(self.flare_cfg))
        self.gp = self.flare_calc.gp_model

        # Default update_threshold if not set
        if self.deal_cfg.update_threshold is None:
            self.deal_cfg.update_threshold = 0.8 * self.deal_cfg.threshold

        self.selected_frames: List = []
        self.dft_count: int = 0
        self.last_dft_step: int = -10**9   # effectively -âˆž

    # ------------------------------------------------------------------
    # basic helpers
    # ------------------------------------------------------------------

    def _frames(self):
        """Generator over all frames, optionally shuffled, with
        atoms.info['frame'] containing the original global index."""
        
        if not self.data_cfg.shuffle:
            # Streaming, non-shuffled mode
            global_idx = 0
            for fname in self.data_cfg.files:
                for at in iread(fname,
                                index=self.data_cfg.index,
                                format=self.data_cfg.format):
                    at.info["frame"] = global_idx
                    global_idx += 1
                    yield at
            return

        # --- Shuffling mode: load all frames first ---
        frames = []
        global_idx = 0

        for fname in self.data_cfg.files:
            for at in iread(fname,
                            index=self.data_cfg.index,
                            format=self.data_cfg.format):
                at.info["frame"] = global_idx
                frames.append(at)
                global_idx += 1

        rng = np.random.default_rng(self.data_cfg.seed)
        rng.shuffle(frames)

        for at in frames:
            yield at

    def _get_species(self):
        """
        Detect species automatically using the DataConfig instance.
        Reads only the first frame from the first file.
        """
        for fname in self.data_cfg.files:
            for atoms in iread(fname, index=self.data_cfg.index, format=self.data_cfg.format):
                return sorted(set(atoms.get_atomic_numbers().tolist()))

    def _extract_dft(self, ase_atoms):
        """
        Extract DFT forces / energy / stress from a frame.

        Assumes the extxyz was written with energies and forces and that
        ASE has attached a SinglePointCalculator to atoms.calc.
        """
        if ase_atoms.calc is None:
            raise RuntimeError(
                "Frame has no calculator attached. Make sure your extxyz "
                "contains energies/forces so ASE builds a SinglePointCalculator."
            )

        res = ase_atoms.calc.results
        forces = np.array(res["forces"])
        energy = float(res.get("energy", ase_atoms.info.get("energy", 0.0)))
        stress = res.get("stress", None)

        return forces, energy, stress

    def _print_progress(self, step: int):
        msg = f"[DEAL] Examined: {step+1} | Selected: {self.dft_count}"
        sys.stdout.write("\r" + msg)
        sys.stdout.flush()

    # ------------------------------------------------------------------
    # main loop
    # ------------------------------------------------------------------

    def run(self) -> None:
        for step, ase_frame in enumerate(self._frames()):
            # 1) DFT labels from original ASE frame
            dft_forces, dft_energy, dft_stress = self._extract_dft(ase_frame)

            # 2) Convert to FLARE_Atoms for SGP calculations & uncertainties
            atoms = FLARE_Atoms.from_ase_atoms(ase_frame)
            # 2a) INITIALIZATION: if GP has no training data, use first frame
            #     to bootstrap the model (no uncertainty check).
            if len(self.gp.training_data) == 0:
                self._update_gp(
                    atoms=atoms,
                    train_atoms=list(range(len(atoms))),
                    dft_frcs=dft_forces,
                    dft_energy=dft_energy,
                    dft_stress=dft_stress,
                )
                self.last_dft_step = step
                self._store_selected_frame(step, ase_frame,
                                           target_atoms=list(range(len(atoms))))
                continue

            # 3) Predict with SGP and compute uncertainties
            atoms.calc = self.flare_calc
            _ = atoms.get_forces()   # triggers GP eval and stores stds internally

            std_in_bound, target_atoms = is_std_in_bound(
                self.deal_cfg.threshold * -1, # threshold = - std_tolerance_factor
                self.gp.force_noise,
                atoms,
                max_atoms_added=self.deal_cfg.max_atoms_added,
                update_style="threshold",
                update_threshold=self.deal_cfg.update_threshold,
            )

            steps_since_last = step - self.last_dft_step
            if (not std_in_bound) and (steps_since_last >= self.deal_cfg.min_steps_with_model):
                # Select this frame & update GP
                self.last_dft_step = step
                self._store_selected_frame(step, ase_frame, target_atoms)
                self._update_gp(
                    atoms=atoms,
                    train_atoms=list(target_atoms),
                    dft_frcs=dft_forces,
                    dft_energy=dft_energy,
                    dft_stress=dft_stress,
                )
            
            # ========== print progress ==========
            self._print_progress(step)

        # newline so terminal prompt doesn't collide with progress line
        print('')

        # ------------------------------------------------------------------
        # outputs
        # ------------------------------------------------------------------
        if self.selected_frames:
            out_xyz = f"{self.deal_cfg.output_prefix}_selected.xyz"
            write(out_xyz, self.selected_frames)
            if self.deal_cfg.verbose:
                print(f"[OUTPUT] Saved selected frames to: {out_xyz}\n")
            try:
                create_chemiscope_input(
                    trajectory=out_xyz,
                    filename=f"{self.deal_cfg.output_prefix}_chemiscope.json.gz",
                    colvar=self.data_cfg.colvar, 
                    verbose=self.deal_cfg.verbose
                )
            except Exception as exc:
                print(f"[WARNING] Could not write chemiscope file: {exc}")

            if self.deal_cfg.save_gp:
                # Save final SGP model
                self.flare_calc.write_model(f"{self.deal_cfg.output_prefix}_flare.json")
                if self.deal_cfg.verbose:
                    print(f"[OUTPUT] Saved GP model to {self.deal_cfg.output_prefix}_flare.json")
            

    # ------------------------------------------------------------------
    # GP creation and update
    # ------------------------------------------------------------------

    def _get_sgp_calc(self, flare_config):
        """
        Return a SGP_Calculator with sgp from SparseGP
        source: https://github.com/mir-group/flare/blob/master/flare/scripts/otf_train.py
        """
        from flare.bffs.sgp._C_flare import NormalizedDotProduct, SquaredExponential
        from flare.bffs.sgp._C_flare import B2, B3, TwoBody, ThreeBody, FourBody
        from flare.bffs.sgp import SGP_Wrapper
        from flare.bffs.sgp.calculator import SGP_Calculator

        sgp_file = flare_config.get("file", None)

        # Load sparse GP from file
        if sgp_file is not None:
            with open(sgp_file, "r") as f:
                gp_dct = json.loads(f.readline())
                if gp_dct.get("class", None) == "SGP_Calculator":
                    flare_calc, kernels = SGP_Calculator.from_file(sgp_file)
                else:
                    sgp, kernels = SGP_Wrapper.from_file(sgp_file)
                    flare_calc = SGP_Calculator(sgp)
            return flare_calc, kernels

        kernels = flare_config.get("kernels")
        opt_algorithm = flare_config.get("opt_algorithm", "BFGS")
        max_iterations = flare_config.get("max_iterations", 20)
        bounds = flare_config.get("bounds", None)
        use_mapping = flare_config.get("use_mapping", False)

        # Define kernels.
        kernels = []
        for k in flare_config["kernels"]:
            if k["name"] == "NormalizedDotProduct":
                kernels.append(NormalizedDotProduct(k["sigma"], k["power"]))
            elif k["name"] == "SquaredExponential":
                kernels.append(SquaredExponential(k["sigma"], k["ls"]))
            else:
                raise NotImplementedError(f"{k['name']} kernel is not implemented")

        # Define descriptor calculators.
        n_species = len(flare_config["species"])
        cutoff = flare_config["cutoff"]
        descriptors = []
        for d in flare_config["descriptors"]:
            if "cutoff_matrix" in d:  # multiple cutoffs
                assert np.allclose(np.array(d["cutoff_matrix"]).shape, (n_species, n_species)),\
                    "cutoff_matrix needs to be of shape (n_species, n_species)"

            if d["name"] == "B2":
                radial_hyps = [0.0, cutoff]
                cutoff_hyps = []
                descriptor_settings = [n_species, d["nmax"], d["lmax"]]
                if "cutoff_matrix" in d:  # multiple cutoffs
                    desc_calc = B2(
                        d["radial_basis"],
                        d["cutoff_function"],
                        radial_hyps,
                        cutoff_hyps,
                        descriptor_settings,
                        d["cutoff_matrix"],
                    )
                else:
                    desc_calc = B2(
                        d["radial_basis"],
                        d["cutoff_function"],
                        radial_hyps,
                        cutoff_hyps,
                        descriptor_settings,
                    )

            elif d["name"] == "B3":
                radial_hyps = [0.0, cutoff]
                cutoff_hyps = []
                descriptor_settings = [n_species, d["nmax"], d["lmax"]]
                desc_calc = B3(
                    d["radial_basis"],
                    d["cutoff_function"],
                    radial_hyps,
                    cutoff_hyps,
                    descriptor_settings,
                )

            elif d["name"] == "TwoBody":
                desc_calc = TwoBody(cutoff, n_species, d["cutoff_function"], cutoff_hyps)

            elif d["name"] == "ThreeBody":
                desc_calc = ThreeBody(cutoff, n_species, d["cutoff_function"], cutoff_hyps)

            elif d["name"] == "FourBody":
                desc_calc = FourBody(cutoff, n_species, d["cutoff_function"], cutoff_hyps)

            else:
                raise NotImplementedError(f"{d['name']} descriptor is not supported")

            descriptors.append(desc_calc)

        # Define remaining parameters for the SGP wrapper.
        species_map = {flare_config.get("species")[i]: i for i in range(n_species)}
        sae_dct = flare_config.get("single_atom_energies", None)
        if sae_dct is not None:
            assert n_species == len(
                sae_dct
            ), "'single_atom_energies' should be the same length as 'species'"
            single_atom_energies = {i: sae_dct[i] for i in range(n_species)}
        else:
            single_atom_energies = {i: 0 for i in range(n_species)}

        sgp = SGP_Wrapper(
            kernels=kernels,
            descriptor_calculators=descriptors,
            cutoff=cutoff,
            sigma_e=flare_config.get("energy_noise",0.1),
            sigma_f=flare_config.get("forces_noise",0.05),
            sigma_s=flare_config.get("stress_noise",0.1),
            species_map=species_map,
            variance_type=flare_config.get("variance_type", "local"),
            single_atom_energies=single_atom_energies,
            energy_training=flare_config.get("energy_training", True),
            force_training=flare_config.get("force_training", True),
            stress_training=flare_config.get("stress_training", True),
            max_iterations=max_iterations,
            opt_method=opt_algorithm,
            bounds=bounds,
        )

        flare_calc = SGP_Calculator(sgp, use_mapping)
        return flare_calc, kernels

    def _store_selected_frame(self, step: int, ase_frame, target_atoms: Sequence[int]):
        """Keep a copy of the selected ASE frame for writing to XYZ."""
        sel = ase_frame.copy()
        sel.info["step"] = step
        if "frame" not in sel.info:
            sel.info["frame"] = step
        sel.info["target_atoms"] = np.array(target_atoms, dtype=int)
        self.selected_frames.append(sel)
        self.dft_count += 1

    def _update_gp(
        self,
        atoms,
        train_atoms: Sequence[int],
        dft_frcs: np.ndarray,
        dft_energy: float | None = None,
        dft_stress: np.ndarray | None = None,
    ) -> None:
        """
        Update the SGP using DFT forces (and optionally energies/stress)
        on the current FLARE_Atoms structure.

        This mirrors original update gp from FLARE OTF, but without
        wall-time logging or mapping.
        """
        # Convert stress into FLARE convention if present
        flare_stress = None
        if dft_stress is not None:
            dft_stress = np.asarray(dft_stress)
            # allow either 3x3 tensor or 6-vector from ASE
            if dft_stress.shape == (3, 3):
                xx, yy, zz = dft_stress[0, 0], dft_stress[1, 1], dft_stress[2, 2]
                yz, xz, xy = dft_stress[1, 2], dft_stress[0, 2], dft_stress[0, 1]
                dft_stress_voigt = np.array([xx, yy, zz, yz, xz, xy])
            else:
                dft_stress_voigt = dft_stress

            # ASE uses +sigma; FLARE uses -sigma in this convention
            flare_stress = -np.array(
                [
                    dft_stress_voigt[0],
                    dft_stress_voigt[5],
                    dft_stress_voigt[4],
                    dft_stress_voigt[1],
                    dft_stress_voigt[3],
                    dft_stress_voigt[2],
                ]
            )

        if self.deal_cfg.force_only:
            dft_energy = None
            flare_stress = None

        # Store a copy of the structure, attach DFT labels via SinglePointCalculator
        struc_to_add = deepcopy(atoms)

        sp_results = {"forces": dft_frcs}
        if dft_energy is not None:
            sp_results["energy"] = dft_energy
        if flare_stress is not None:
            sp_results["stress"] = flare_stress

        struc_to_add.calc = SinglePointCalculator(struc_to_add, **sp_results)

        # Update GP database 
        self.gp.update_db(
            struc_to_add,
            dft_frcs,
            custom_range=list(train_atoms),
            energy=dft_energy,
            stress=np.zeros(6) if flare_stress is None else flare_stress,
        )

        # Update internal L and alpha
        self.gp.set_L_alpha()

        # Train hyperparameters
        if self.deal_cfg.train_hyps:
            self.gp.train(logger_name=None)


